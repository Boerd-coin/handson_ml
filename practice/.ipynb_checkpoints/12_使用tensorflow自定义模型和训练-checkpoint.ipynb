{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1178ea9e-9a78-4185-83df-d253143a46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.4 is required in this notebook\n",
    "# Earlier 2.x versions will mostly work the same, but with a few bugs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.4\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1d9bf-c834-40a8-b6e6-89eb94a19410",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 张量操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8e204-59fd-4533-9c05-f4d27f684699",
   "metadata": {},
   "source": [
    "### 张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19ddf7-6658-4768-bcba-3d10d0a93e57",
   "metadata": {},
   "source": [
    "使用`tf.constant`创建常数张量，该类型张量的元素无法更改  \n",
    "通常数学操作，如使用`tf.add`与`tf.math.add`指向的是同一个函数，这是为了简化代码，但是也有不一样的。如对数只能写`tf.math.log`  \n",
    "通常tf的张量运算函数名称与numpy的是一样的，但也有不一样的，比如`np.mean`对应的是`tf.reduce_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7adb75-8425-46e5-a277-19190b07afb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix\n",
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904aeff0-7684-483a-af1e-9333d80744e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e598903-a7de-46ae-8f22-e96e2401e845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a0b38-63f0-4e5d-96d9-e9507030dd14",
   "metadata": {},
   "source": [
    "### 张量索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc862e2-50d2-474c-955d-8b5421bc8694",
   "metadata": {},
   "source": [
    "tf中张量的索引方式与在numpy中是十分相似的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e385ca-551f-419b-bd9e-2a98a27abb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03d304b-0f00-4581-a147-9c5d23429b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5de86ef-49a8-4082-b615-ff10278dfbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd52ad0-627a-4f1e-8a56-6f85a6cc7568",
   "metadata": {},
   "source": [
    "### 张量操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da401330-3146-442d-b11b-3df28b9e945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b681404-7457-42ad-8d5c-f4613b6e0aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9ddae3-0c87-4894-bd09-9a6b4f0d4745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵乘法\n",
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f4798-6f30-4fee-b095-c56b1da6fa2c",
   "metadata": {},
   "source": [
    "### 使用`keras.backend`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ad02b-08b3-42b0-bf5f-7e733f5657bd",
   "metadata": {},
   "source": [
    "keras.backend中也有像tf的诸如square()、exp()的函数，但是如果在tf.keras中使用这些keras的函数，那么其实还是会指向tf的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f4b423-c98f-4c8f-ad80-be5918c1f0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可见使用tf.keras.backend的运算函数其实还是tf的\n",
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb037f-91b8-4b7e-a49d-bfc51a285dd6",
   "metadata": {},
   "source": [
    "### 导入\\导出为Numpy数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e80d52-ae4a-495e-8dd3-cebeb47a625c",
   "metadata": {},
   "source": [
    "<b><font color=red>注意:</font></b> numpy中的数组默认使用的64位精度，但是tf的张量默认使用32位精度。  \n",
    "这是因为32位精度在神经网络训练中就已经绰绰有余了，而且还可以减少使用的内存，保障运行速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0861524-4379-4e53-9a8b-1cae28bdc519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13e42b71-f900-4fcb-bdb7-91820e8e59e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量转换成numpy数组\n",
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1d63a6-19be-4c26-9203-ba5b554fa69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf函数可以处理numpy数组\n",
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc87334-ae1a-4464-a75c-803738da9d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy函数可以处理tf张量\n",
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075a961-f753-41cc-b5dc-47c548165fcb",
   "metadata": {},
   "source": [
    "### 类型转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b79f7ee-e2dd-46cd-b844-4e14572005ff",
   "metadata": {},
   "source": [
    "在tf中，不会自动转换张量类型，有点像静态语言  \n",
    "比如不能把浮点张量与整数张量相加，甚至不能相加32位和64位浮点数  \n",
    "所以如果张量要与numpy数组进行运算，记得确保位数一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34a6c982-c1cf-43de-bfd5-f6c8568c4cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "# 整数与浮点数张量无法运算\n",
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "507b01e8-8b9f-469c-bcd5-4df76bdc9e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "# 32位浮点数与64位浮点数无法运算\n",
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "121d706d-1c25-413c-b4a1-feea2e4e0b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果需要类型转换，可以使用tf.cast()\n",
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff718e-f544-4a26-b85b-5479b04376a5",
   "metadata": {},
   "source": [
    "### 字符串张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2074c76-e011-438a-bf5d-1b50577facf5",
   "metadata": {},
   "source": [
    "表示字节字符串，而不是Python的Unicode字符串  \n",
    "tf.strings是原子级的，所以不显示长度，但若将其用Unicode代码表示，就可以显示长度了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fc5c258-3d12-4241-b571-7c7100cdc5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字节字符串\n",
    "tf.constant(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2d8557b-82ea-4e6b-9ef7-f1b623820067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于UTF-8代码保存字符串\n",
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57044a41-0c8e-4656-834d-6c0d2dff2b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于Ucicode代码保存字符串，可以在shape属性中显示字符串长度\n",
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8986f0ca-3570-4124-9acc-f07cc13f28bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tf.string对字符串进行编码，将Unicode字符串转换为UTF-8编码\n",
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "# 基于UTF8字符显示字符串长度\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "056fe6cb-edb9-49ae-9ad1-1d5fe200fea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ffd1b-5ef9-4c49-902c-2564f889704f",
   "metadata": {},
   "source": [
    "### 字符串数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55e36010-5347-485b-ad9c-d33430e51c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5118de0b-0596-4c01-9bbf-3996a8040d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07a456d4-4e13-4878-8925-3a91471729ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
       " [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "366d4a30-ea70-4968-b037-35032feabf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa3b4a-18f0-4d08-b033-2d93d2380ce9",
   "metadata": {},
   "source": [
    "### 不规则张量（Ragged tensors）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b9c47c-2766-4928-bfd0-c0edf2905f2d",
   "metadata": {},
   "source": [
    "表示张量列表的静态列表，大小不可变，其中每个向量都有相同的形状和数据类型  \n",
    "tf.ragged包含不规则张量的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "244038ec-9c40-4db5-8a26-5612be64e3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6d494ea-3ef0-4e76-98a0-9b73efec121a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0],\n",
       "       [   65,    66,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0],\n",
       "       [   67,     0,     0,     0,     0,     0]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以行的形式加入三行，长度不够的地方用0填充\n",
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "tf.concat([r, r2], axis=0).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb9e6501-c06b-4725-9bd3-ac4157787e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,    68,    69,    70],\n",
       "       [   67,   111,   102,   102,   101,   101,    71],\n",
       "       [   99,    97,   102,   102,   232,     0,     0],\n",
       "       [21654, 21857,    72,    73,     0,     0,     0]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以列的形式填充3列，优先填充目标行长度不够的位置（被0填充的位置），可以增加新的列\n",
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "tf.concat([r, r3], axis=1).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84cccc80-72ea-4e74-a820-6e02610f1d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用UTF-8编码\n",
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a135349-fead-4ae1-8ee5-195a9df2ce1c",
   "metadata": {},
   "source": [
    "### 稀疏张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1697d83f-032e-4d7d-bc6a-0a419d564edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]], # 非零值的位置\n",
    "                    values=[1., 2., 3.], # 菲零值\n",
    "                    dense_shape=[3, 4]) # 形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "348d6cec-95a7-4714-8dab-a2773e1d8724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf8a9376-9687-4c6d-992b-5982aa980263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a3e2ce0-dfd8-4249-b1c7-a4f9ad21ce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 稀疏矩阵支持乘除法\n",
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dff7bee-c97a-4658-b511-dc72d64e2916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "# 稀疏矩阵不支持加减操作\n",
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "652d618d-434d-452d-87c5-59edd6f270ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 除非先将稀疏矩阵转换成dense矩阵\n",
    "s4 = tf.sparse.to_dense(s) + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0c07709-86d7-4388-9f13-c96be8b0bc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵乘法需调用sparse_dense_matmul方法\n",
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4651728-46c2-4e9c-a8ed-86bf3f145eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# 在构造稀疏矩阵的时候，最好是按照行和列的顺序定义各个位置的元素，不要像下面这样\n",
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "363c1cc5-320c-48a3-b783-ad163cc4d116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] is out of order. Many sparse ops require sorted indices.\n",
      "  Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "# 否则就没办法转换成dense矩阵了\n",
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b597d02-7862-4e05-8f78-f2e2bebd318f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 但是可以使用reorder方法来重新排序各元素的定义的顺序\n",
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32798cde-fbb9-445c-b800-81e841f94377",
   "metadata": {},
   "source": [
    "### 集合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801f401-8f3a-4758-8ca2-b884aaadc351",
   "metadata": {},
   "source": [
    "就像Python中集合那样，可以合并重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca7cdbed-59f6-4b63-b805-76fbc5c20652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "# 得到最后\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5b75d-97eb-41b1-b776-258d8da695bf",
   "metadata": {},
   "source": [
    "### 变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52526991-5223-485d-8088-22555b41da93",
   "metadata": {},
   "source": [
    "前面的张量都是不能修改的，这就意味着其不能作为反向传播权重的载体  \n",
    "变量类型的张量可以担负这个任务，但是一般不用使用者亲自修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff26a884-cc61-4f75-a21c-ef329adb39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b88a5582-1a2d-4424-b1b6-1c9615272b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用assign方法对张量进行修改\n",
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dee5663-1d2b-4419-87be-20b8c7f5a52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定点分配值\n",
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b331423-1188-47c6-bc28-e58eeb422c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在切片中分配数值\n",
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e767fd24-eb8d-4db9-953a-6ab42eb9b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "# 不能直接指定\n",
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0455fdc-6ca0-4c44-9ba4-c21cc743ea72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用scatter_nd_update方法也可以修改值\n",
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8574eca1-c099-4e7d-b5cc-0f258cee37cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 再或者向scatter_update方法中传入IndexedSlices实例来修改\n",
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8544ac-ce26-4a0d-950b-2ee66dab3d55",
   "metadata": {},
   "source": [
    "### 张量数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb901ae5-9564-4aa3-8fc9-f8ff5975e282",
   "metadata": {},
   "source": [
    "有点像动态数组，可以后续添加新的行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b92ba59-7fb0-4d08-a5ad-b1f5dd1eaecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69edce00-f488-4e3a-bde2-de4c16ea3771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从数组中取出第二行\n",
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "394c7203-9b2a-4fb1-a563-f64f8c3bb8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二行元素被取走，用0填充原来的位置\n",
    "# 以栈的形式展示数组\n",
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07330825-0e9d-4059-b0d4-cec6d6e1b755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15cb6dbc-d9a0-4cdc-888f-4aa0f237b085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c9268-6719-4415-b149-34a99f7da758",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 自定义模型和训练算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673cca20-e86e-452f-966f-cc53dc496bf6",
   "metadata": {},
   "source": [
    "### 自定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca04c7-1ab4-4ab3-8c6a-f6f1d162e364",
   "metadata": {},
   "source": [
    "以一个回归神经网络为例，数据的话还是拿加利福利亚房产数据  \n",
    "首先要强调的是：如果想要自定义的损失函数可以从tensorflow的图形功能中受益，就要在函数中尽可能使用向量化实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33400c7c-3ab6-4a03-ab0a-19b6a2466816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfab61af-72ce-4b2c-8e4e-d08a903741b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义一个损失函数：huber损失函数，虽然keras.loss中有它的实现。但是这里非要自己做\n",
    "# 注意这里的向量要尽可能用tf的张量函数来表示\n",
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86822f09-f213-4449-b9ac-c1e841afd7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71d50527-8273-4ccd-a809-9760398f4762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6235 - mae: 0.9953 - val_loss: 0.2862 - val_mae: 0.5866\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2197 - mae: 0.5177 - val_loss: 0.2382 - val_mae: 0.5281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c4f4c4e80>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# 来建立一个非常简单的网络\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 这里输入自定义的huber损失函数\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041346c-8db9-4510-a4c2-b61ef8fe8e19",
   "metadata": {},
   "source": [
    "### 保存\\加载使用了自定义对象的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dcfb58-c93d-4fab-9b65-22f3ab78a60e",
   "metadata": {},
   "source": [
    "在脚本中使用自定义的损失函数很方便，但是要是加载一个使用了自定义函数的模型就麻烦了，因为在保存模型的时候是不会把自定义的对象也给保存了的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45d775a6-c4ea-4bb4-9392-f38999420aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30adecf6-0e84-467c-a60d-9696e8cd94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型在保存的时候会将自定义的对象名称当做一个字典的键保存起来\n",
    "# 在加载的时候只需要向字典中对应的键传递相应的对象就行了\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c7fd966-a14a-456a-a20d-2d4391afd12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2054 - mae: 0.4982 - val_loss: 0.2209 - val_mae: 0.5050\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.1999 - mae: 0.4900 - val_loss: 0.2127 - val_mae: 0.4986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c5dce7f70>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可见此时网络是可以正常训练的\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bab37d96-ee6f-4b0a-b98b-e8e397e499f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果想要改变huber函数中的误差的阈值，可以这么写\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce5102c8-84d0-4b25-9991-35a11d6a270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.2226 - mae: 0.4892 - val_loss: 0.2539 - val_mae: 0.4907\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2184 - mae: 0.4844 - val_loss: 0.2372 - val_mae: 0.4879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d2adc7df0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 然后被这样调用\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "242eaa70-2709-4a9a-ab06-e6806ea033d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 但是有一个问题，那就是在保存模型的时候不会保存自定义的阈值\n",
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")\n",
    "\n",
    "# 并且在加载的时候键仍是huber_fn，需要手动指定阈值\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90083dd5-c260-4879-892f-b1f779bd4b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2147 - mae: 0.4800 - val_loss: 0.2133 - val_mae: 0.4654\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2119 - mae: 0.4762 - val_loss: 0.1992 - val_mae: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c5dce7e50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9fc1f16-4455-47d3-9d6d-83893859ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当然对于这种情况也不是没有办法解决\n",
    "# 那就是自定义一个Huber损失的类，继承自keras.losses.Loss类\n",
    "# 记得要实现get_config方法，这样就可以把想要的超参数保存自动保存下来了\n",
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        # 注意这里调用了父类的get_config方法\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1b47787-b99f-49b9-b0ce-08e54a451681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7095 - mae: 0.8863 - val_loss: 0.3378 - val_mae: 0.5485\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2416 - mae: 0.5083 - val_loss: 0.2660 - val_mae: 0.5089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d32431100>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 新建一个模型来举例\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0541964e-49fa-4ad6-855a-bdf42a287756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2286 - mae: 0.4970 - val_loss: 0.2120 - val_mae: 0.4723\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2216 - mae: 0.4904 - val_loss: 0.2045 - val_mae: 0.4725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d41111f10>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")\n",
    "\n",
    "# 可见此时再加载，键就是HuberLoss了，并且也不用再重新输入HuberLoss的超参数阈值了，只需要输入类名就行了\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a4970a0d-9a1d-4f48-9415-18f3402af506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查一遍看看阈值是不是后来定义的2，而不是默认的1\n",
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78462d8a-974c-42bf-805c-e0bc253a6088",
   "metadata": {},
   "source": [
    "### 自定义激活函数、初始化、正则化和约束"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be9271-acef-4473-8646-b49088e787ce",
   "metadata": {},
   "source": [
    "只需要特定的输入输出，自定义的函数就能作为keras大多数的功能如：损失、正则化、约束、初始化、指标、激活函数、层甚至完整的模型  \n",
    "参数的类型取决于自定义函数的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d60c0fb-e605-40f7-9b90-c09048a9a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 激活函数自定义\n",
    "# 等同于tf.nn.softplus(z)和keras.activations.softplus(z)\n",
    "def my_softplus(z): \n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "# 自定义初始化\n",
    "# 等同于keras.initializers.glorot_normal()\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "# 自定义l1正则项\n",
    "# 等同于keras.regularizers.l1(0.01)\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "# 确保权重全为正的自定义约束\n",
    "# 等同于keras.contraints.nonneg()或tf.nn.relu()\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e4117113-1cc9-450a-9f0b-a867d989751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2135f2e2-eb59-45d7-9e1f-aeb6c33a89be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.3809 - mae: 0.8429 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6669 - mae: 0.5528 - val_loss: 2.7497 - val_mae: 0.5489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d3240eb80>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以用自定义的函数组成一个模型\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a86ea69-cbff-404a-bc27-58def24c7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在加载带有自定义函数的模型时，同样需要在对应字典的键映射对应的函数\n",
    "model.save(\"my_model_with_many_custom_parts.h5\")\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3357989-3ef7-4c9e-8871-8612dfee0390",
   "metadata": {},
   "source": [
    "但是如果像上面那样定义函数，函数的超参数是不能与模型一起保存的  \n",
    "如果想自定义函数的超参数与模型一起保存，就需要继承对应的基类，如：  \n",
    "  \n",
    "正则化：`keras.regularizers.Regularizer`  \n",
    "约束：`keras.constraints.Constraint`  \n",
    "初始化：`keras.initializers.Initializer`  \n",
    "层或激活函数：`keras.layers.Layer`  \n",
    "  \n",
    "当然还有需要自定义一些方法：  \n",
    "如果自定义的是损失、层或激活函数或模型，需要自定义call()方法；  \n",
    "如果自定义的是正则化、初始化或约束，需要自定义__call__()方法。\n",
    "指标的情况就比较特殊了，暂时不提"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "976e2003-da9f-4749-b038-2b861a43ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义正则化类\n",
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    # 可以看到这里没有用父类的get_config()方法，这是因为父类就没有这个方法\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "688e1883-5fc2-4a2b-80c9-1ad60c0d3503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.7210 - mae: 0.9218 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6100 - mae: 0.5358 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d4f3eed60>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置factor为0.01\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07f7a435-43f1-47d4-821a-2c576e643f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再保存后导入，此时的factor肯定是0.01\n",
    "model.save(\"my_model_with_many_custom_parts.h5\")\n",
    "\n",
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a508d56e-c82d-417a-8f98-503bf19d9af2",
   "metadata": {},
   "source": [
    "## 自定义指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b8de369-0ca3-405f-bef6-f6009c5190e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8032 - huber_fn: 0.8032\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2449 - huber_fn: 0.2449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d51c862b0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先整一个模型为例\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 首先试试将损失函数和指标都设置为huber\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])\n",
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9e5b6-4851-4ce4-98a2-32a9b1820343",
   "metadata": {},
   "source": [
    "**Note**: 可以看到上面的损失函数和指标都是同一个函数，每次迭代损失和指标误差都是一样的。但是也有即使损失和指标用的是同一个函数但每次迭代的值都不一样的情况，这通常是由浮点计算的误差导致的，即因计算顺序的不同而导致微小的误差。  \n",
    "若使用了样本权重，则除了浮点计算误差外还会有其他的误差，这来源于损失函数与指标在模型中的计算方法的不同：  \n",
    "* 每一个轮次的损失是所有批次损失的平均值，每个批次损失是所有实例（行）损失的加权和再除以批次大小（这里指的可不是加权平均）\n",
    "* 每一个轮次的指标是所有批次损失的平均值，每个批次损失是所有实例（行）损失的加权和再除以批次大小后再除权重之和（这里就是加权平均了）  \n",
    "  \n",
    "如果有公式来表示的话，就是loss = metric * 所有样本的权重平均值（还得加上一些浮点计算误差）  \n",
    "也就是说，在像刚才那样样本权重全都为1的时候loss和metric是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fbb90007-5866-42c8-95ed-af3f1549beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.1155 - huber_fn: 0.2344\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.1121 - huber_fn: 0.2266\n"
     ]
    }
   ],
   "source": [
    "# 还拿刚才的模型举例，这次给每个实例（行）都配上了随机权重\n",
    "sample_weight = np.random.rand(len(y_train))\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])\n",
    "# 可以看到，这回每个轮次计算的loss和metric不一样了，尽管使用的是一样的函数\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "276301d0-662e-4582-8fc8-425a23f8fb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11553215235471725, 0.1163423971241267)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 手动再给metric乘上所有样本权重平均值，可以看到，这回loss和metric差不多了\n",
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f5bd437-bfd3-421d-8c55-abdc4cb67199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2344445437192917, 0.2265670895576477]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"huber_fn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c1340-fe16-468b-b431-abe357b81fec",
   "metadata": {},
   "source": [
    "### 流式指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d96b4-defa-4bd8-a92d-c2330cadc471",
   "metadata": {},
   "source": [
    "指标的计算一般都是分别计算每个轮次的分数，然后将所有轮次分数的平均值作为一次完整训练的指标  \n",
    "但是有时这样的计算时不行的，不能反映模型真实的表现，举个栗子：  \n",
    "  \n",
    "现要考察一个二元分类器的精度，指标为：预测为真正确的数量 除以 预测为真的数量\n",
    "- 第一轮次：5个正预测，4个是正确的，即80%精度  \n",
    "- 第二轮次：3个正预测，全都不对，0%精度\n",
    "按照正常指标的计算方法，本次完整（数据集）计算的精度为40%  \n",
    "  \n",
    "但这是不准确的，因为两个轮次同属一个数据集，如果要考察一整个数据集的准确率，那应该是\n",
    "- 8个正预测(5+3)，4个是正确的，即50%精度  \n",
    "\n",
    "而这就是流式指标，不会只分别计算单个轮次的分数，而是将整个数据集当做一个整体去算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1fd2f4f7-9fd9-4872-b724-e51da8726a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Precision类就能实现刚才的例子\n",
    "precision = keras.metrics.Precision()\n",
    "# 第一轮次分别输入真实值与预测值，可得到第一轮次的精度，即80%\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6df6203c-274f-4fe4-82e1-cbf4cf0e69d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接着输入第二轮次的真实值与预测值，可得到两个轮次作为一个整体的精度，即50%，而不是40%\n",
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e63a6ab1-c91a-41da-bd45-6e17a4012707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用result方法可随时得到当前的精度\n",
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "24dc54ae-d1c3-4f58-a6b2-a68a99c7aef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables属性可以得到所有实例的属性，如下可看到代表预测为真正确的数量 和 预测为真的数量，即true_positives、false_positives\n",
    "# 初始值都为0\n",
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb67d56d-a5cf-419e-997b-6ebc76f81e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 还可以重置\n",
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048a6a1-3097-41db-8ce7-e1e49aec5f28",
   "metadata": {},
   "source": [
    "<b><font color=black>自定义一个流式指标</font></b>  \n",
    "想要自定义一个属于自己的流式指标，就需要继承keras.metrics.Metric类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9bd5b208-e1ea-47ab-95ae-c8a0b0451c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先来自定义一个流式Huber指标\n",
    "# 所有实例的Huber误差之和 除以 实例总数 就是最终的Huber分数\n",
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        # 在构造函数中一定要实现父类的构造函数\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        # 同时要使用父类的add_weight方法自定义需要keras跨越各个轮次追踪的变量\n",
    "        # 这里自定义的变量分别是 Huber误差之和 和 实例总数\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # 一定要实现update_state方法，keras将总是调用这个函数来更新各个变量的变化\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        # 使用变量的assign_add方法更新变量数值\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    \n",
    "    def get_config(self):\n",
    "        # 当然还得实现get_config方法，在输出基类的配置参数的基础上再输出threshold参数值\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "df74c761-4ec5-4ead-acfa-adaf996f8d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 来验证一下\n",
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9bfca1d7-1aad-4cf4-9d6d-8673b15899ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "# 可以正常使用result函数\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "361ddc3d-adfa-4465-b86a-9adf0d0339ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b09dc49-986e-415b-9098-2eeb90128c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37847a9e-bd05-45ec-a227-9da2b5b49797",
   "metadata": {},
   "source": [
    "<b><font color=black>看看自定义的HuberMetric在模型中是否能正常运行</font></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1d3b0285-df21-4747-aee2-a30715d2c87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9459 - huber_metric_1: 0.9459\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2585 - huber_metric_1: 0.2585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20d51f5e610>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])\n",
    "\n",
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bce31571-3f90-44c8-9fa7-1dddcace3532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存的话，自定义指标的参数也会随着一起保存\n",
    "model.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "452ae6f1-f52f-4a55-9341-1fb02e2df31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以看到，在载入模型的时候不用再输入指标的参数\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3272a3-f583-4c79-a836-4c8359db9866",
   "metadata": {},
   "source": [
    "**Warning**: 在TF 2.2, tf.keras默认将metric列表的第一个改成了loss，也就是`model.metrics`中索引为0的位置 (see [TF issue #38150](https://github.com/tensorflow/tensorflow/issues/38150)). 这就迫使我们使用`model.metrics[-1]`而不是`model.metrics[0]`调用`HuberMetric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36ce4a5d-550c-4576-b0bf-0ff7a9922afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d69571f0-2bdb-4263-b810-0e805dbbddb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'huber_metric_1']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9aa39-f340-4ea2-9b2f-5399eb855dd4",
   "metadata": {},
   "source": [
    "<b><font color=black>一种更简单实现HuberMetric流式指标的方法</font></b>  \n",
    "主要是通过继承流式指标`keras.metrics.Mean`来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "58d790a3-2d2f-4099-8751-25eea505c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.metrics.Mean中就有total和count这两个可跟踪的变量\n",
    "# 输出结果的时候也是计算total / count\n",
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        # 使用父类的方法更新变量\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f0684cf-acb8-4ceb-95f2-ca3226c5e46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.4838 - HuberMetric: 0.9553\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.1225 - HuberMetric: 0.2418\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])\n",
    "\n",
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5215a298-ed7d-4395-a4f8-78d8b06415af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48375096917152405, 0.48375112251397656)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顺便再验证一下loss和指标在有样本权重的情况下的区别\n",
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e766936-3b72-4a15-8b5e-8fe8de7cf615",
   "metadata": {},
   "source": [
    "## 自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce760667-3f4e-4817-925e-88782041797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果只是想创建一个简单的、不带权重的层，可以使用keras.layers.Lambda类来实现\n",
    "# 比如以下这个层，对任何输入数据做指数处理。一般这种对输入做指数处理的情况时说明要预测的值具有不同的尺度，如0.001、10、100\n",
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e7631cc7-dd8f-4ed6-9f64-617b42fbfc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787948, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试一哈\n",
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0b2d4506-b02b-42b2-b623-8419f3c0ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 5.6978 - val_loss: 5.3965\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 5.3811 - val_loss: 4.6626\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.6537 - val_loss: 2.2656\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6514 - val_loss: 1.1740\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0789 - val_loss: 0.8262\n",
      "162/162 [==============================] - 0s 924us/step - loss: 0.8775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8775125741958618"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以直接将自定义的层放进顺序或其他API形式的模型中\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f9ccf8-fb1f-4940-91e1-37839c187412",
   "metadata": {},
   "source": [
    "但是如果要实现比较复杂操作的、有权重的层，就需要继承`keras.layers.Layer`类了，继承之后必须要实现以下3个方法：  \n",
    "- build(input_shape)：这是定义层各连接权重的方法，在定义权重完成后必须设置`self.built = True`，但是这可以使用`super().build()`来实现  \n",
    "- call(x)：这是决定层逻辑的方法，决定向激活函数中输入怎样的矩阵  \n",
    "- compute_output_shape(input_shape)：返回层输出张量的形状，这个方法通常不实现也是可以的，keras可以自动推断出输出的形状，但是如果该层改变了输入张量的性状，就必须定义一下这个方法，也就是说层是动态的时候。默认的是输出形状与输入形状相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "39bd8b84-0d49-44bc-953f-6223d91fc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # 神经元的个数\n",
    "        self.units = units\n",
    "        # 使用keras.activations.get方法得到激活函数\n",
    "        # 因为当输入字符串如activation = ‘relu’时就需要这个方法来识别是什么函数了\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        # 正常神经元的连接权重，是矩阵\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        # 偏置神经元的连接权重，是一个向量，这里初始权重为0\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        # 父类的build方法在最后执行\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        # 层的输入X与正常神经元做矩阵乘法后加上偏置向量\n",
    "        # 最后将矩阵输入给激活函数来输出到下一层\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        # 这是输出的形状，输入的最后一个维度需要被替换成神经元的个数\n",
    "        # 就比如这是各输出层，只有一个神经元，输入为(8, 10), 输出自然应为(8, 1)\n",
    "        # 输入的batch_input_shape是一个tf.TensorShape对象，这里需要先转换成列表修改后再重新定义成tf.TensorShape对象\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                # 这里可以使用过序列化来保存激活函数完整配置\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19b478ab-9314-42e7-8923-db67a8178d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.6812 - val_loss: 2.1800\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5565 - val_loss: 0.9286\n",
      "162/162 [==============================] - 0s 819us/step - loss: 0.4855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4854835569858551"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5f6d2d18-18e8-466e-b68d-0e7e70ecc50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")\n",
    "\n",
    "# 和其他自定义对象一样，在加载的时候需要指明自定义的对象，这里需要指明自定义的层\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "adf9845f-354a-4eb9-9e33-09c4a9bd1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当层有多个输入，多个输出的后需要这样写\n",
    "# 注意：此时这个自定义的层是不能使用顺序API来定义模型的，只能使用其他的API方式来自定模型\n",
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        # 当输入有多个时，输入的X就是包含所有输入的元组\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape) # Debugging of custom layer\n",
    "        # 这里返回几个输出，compute_output_shape就需要返回几个形状\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        # batch_input_shape当然也是有两个，包含在元组里\n",
    "        # 这里假设层的输入与输出一样，也就是变量数量与神经元数量一致，所以就不用改了，直接输出就行\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "25acd29a-bde6-4301-879d-ed708e4142a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "# 使用函数API模型来测试一下才定义的2输入2输出层\n",
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "355fa13a-1b02-4459-ae26-4b4b322d9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要层在训练期间和测试期间的表现不一样，就像dropout层或BatchNormalization层那样\n",
    "# 举个栗子就像下面这个层，在测试的时候会添加高斯噪音，但是在测试的时候就不添加\n",
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        # 其关键就是给call函数添加一个训练参数training，用来判断当前是不是在训练模型\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3647aedb-94f7-409d-b898-6042dcfc05b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 2.3857 - val_loss: 7.6084\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.0571 - val_loss: 4.4599\n",
      "162/162 [==============================] - 0s 857us/step - loss: 0.7560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7559574246406555"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa98b16-2912-4e39-83e7-b3eafb0ff240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_venv",
   "language": "python",
   "name": "tenserflow_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
